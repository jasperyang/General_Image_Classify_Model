{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# -*- encoding=utf-8 -*-\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.applications import *\n",
    "from keras.preprocessing.image import *\n",
    "from tensorflow.python.ops import math_ops\n",
    "import keras\n",
    "\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "import tensorflow as tf\n",
    "\n",
    "#进行配置，使用30%的GPU\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 1\n",
    "session = tf.Session(config=config)\n",
    "\n",
    "# 设置session\n",
    "KTF.set_session(session)\n",
    "\n",
    "path = './data/'\n",
    "batchsize=64\n",
    "\n",
    "import h5py\n",
    "\n",
    "batchsize = 64\n",
    "image_size = (299,299)\n",
    "lambda_func = inception_v3.preprocess_input\n",
    "\n",
    "width = image_size[0]\n",
    "height = image_size[1]\n",
    "input_tensor = Input((height, width, 3))\n",
    "x = input_tensor\n",
    "if lambda_func:\n",
    "    x = Lambda(lambda_func)(x)\n",
    "\n",
    "base_model = InceptionV3(input_tensor=x, weights='imagenet', include_top=False)\n",
    "\n",
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "# and a logistic layer -- let's say we have 200 classes\n",
    "predictions = Dense(30, activation='softmax')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "\n",
    "# 先fine-tune全连接层\n",
    "for layer in base_model.layers[:]:\n",
    "    layer.trainable = False\n",
    "\n",
    "\n",
    "gen = ImageDataGenerator(\n",
    "            rescale=1./255,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True)\n",
    "\n",
    "gen2 = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = gen.flow_from_directory(path+\"image_train\", image_size, shuffle=False,\n",
    "                                          batch_size=batchsize,class_mode='categorical')\n",
    "validation_generator = gen2.flow_from_directory(path+\"image_val\", image_size, shuffle=False,\n",
    "                                         batch_size=batchsize,class_mode='categorical')\n",
    "\n",
    "\n",
    "# train = model.predict_generator(train_generator,100)\n",
    "# test = model.predict_generator(test_generator)\n",
    "\n",
    "# log_loss\n",
    "def log_loss(y_true, y_pred):\n",
    "    epsilon = 1e-7\n",
    "    predictions = math_ops.to_float(y_pred)\n",
    "    labels = math_ops.to_float(y_true)\n",
    "    predictions.get_shape().assert_is_compatible_with(labels.get_shape())\n",
    "    return -(math_ops.reduce_sum(math_ops.multiply(labels,math_ops.log(predictions)+epsilon)))/batchsize\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(lr=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=[log_loss])\n",
    "\n",
    "model.fit_generator(\n",
    "            train_generator,\n",
    "            samples_per_epoch=train_generator.samples,\n",
    "            nb_epoch=50,\n",
    "            validation_data=validation_generator,\n",
    "            nb_val_samples=validation_generator.samples/batchsize)\n",
    "\n",
    "\n",
    "# let's visualize layer names and layer indices to see how many layers\n",
    "# we should freeze:\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "    print(i, layer.name)\n",
    "\n",
    "# we chose to train the top 2 inception blocks, i.e. we will freeze\n",
    "# the first 249 layers and unfreeze the rest:\n",
    "for layer in model.layers[:249]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[249:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "model.compile(optimizer=SGD(lr=0.1, momentum=0.9), loss='categorical_crossentropy',metrics=[log_loss])\n",
    "\n",
    "model.fit_generator(\n",
    "            train_generator,\n",
    "            samples_per_epoch=train_generator.samples,\n",
    "            nb_epoch=50,\n",
    "            validation_data=validation_generator,\n",
    "            nb_val_samples=validation_generator.samples/batchsize)\n",
    "\n",
    "\n",
    "model.save_weights('model/incepV3_e50.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4260 images belonging to 30 classes.\n",
      "Found 1080 images belonging to 30 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:52: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:52: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., validation_data=<keras.pre..., steps_per_epoch=66, epochs=50, validation_steps=16)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " 7/66 [==>...........................] - ETA: 1:21 - loss: 3.2807 - log_loss: 3.2807"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-8531c691f382>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m \u001b[0mload_model_and_finetune\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mInceptionV3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m299\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m299\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'model/incepV3_e50.h5'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'model/incepV3_248.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-31-8531c691f382>\u001b[0m in \u001b[0;36mload_model_and_finetune\u001b[0;34m(MODEL, image_size, model_path, new_model_path, lambda_func)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 nb_val_samples=validation_generator.samples/batchsize)\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2192\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2193\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0menqueuer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2194\u001b[0;31m                 \u001b[0menqueuer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2196\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/utils/data_utils.pyc\u001b[0m in \u001b[0;36mstop\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munfinished_tasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_close_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0m_SHARED_SEQUENCES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/utils/data_utils.pyc\u001b[0m in \u001b[0;36m_close_pool\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    588\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_close_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    468\u001b[0m         \u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'joining pool'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mCLOSE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTERMINATE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_worker_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    471\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/threading.pyc\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    938\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__stopped\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 940\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__block\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    941\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0m__debug__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_note\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s.join(): thread stopped\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/threading.pyc\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0m__debug__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_note\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s.wait(): got it\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def load_model_and_finetune(MODEL,image_size,model_path,new_model_path,lambda_func=None):\n",
    "    width = image_size[0]\n",
    "    height = image_size[1]\n",
    "    input_tensor = Input((height, width, 3))\n",
    "    x = input_tensor\n",
    "    if lambda_func:\n",
    "        x = Lambda(lambda_func)(x)\n",
    "    \n",
    "    base_model = MODEL(input_tensor=x, include_top=False)\n",
    "\n",
    "    # add a global spatial average pooling layer\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    # let's add a fully-connected layer\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    # and a logistic layer -- let's say we have 200 classes\n",
    "    predictions = Dense(30, activation='softmax')(x)\n",
    "\n",
    "    # this is the model we will train\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    # 读取参数\n",
    "    model.load_weights(model_path)\n",
    "    \n",
    "    \n",
    "    for layer in model.layers[:248]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[248:]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    gen = ImageDataGenerator(\n",
    "                rescale=1./255,\n",
    "                shear_range=0.2,\n",
    "                zoom_range=0.2,\n",
    "                horizontal_flip=True)\n",
    "\n",
    "    gen2 = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    train_generator = gen.flow_from_directory(path+\"image_train\", image_size, shuffle=False,\n",
    "                                              batch_size=batchsize,class_mode='categorical')\n",
    "    validation_generator = gen2.flow_from_directory(path+\"image_val\", image_size, shuffle=False,\n",
    "                                             batch_size=batchsize,class_mode='categorical')\n",
    "    \n",
    "    from keras.optimizers import SGD\n",
    "    model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy',metrics=[log_loss])\n",
    "\n",
    "    model.fit_generator(\n",
    "                train_generator,\n",
    "                samples_per_epoch=train_generator.samples,\n",
    "                nb_epoch=50,\n",
    "                validation_data=validation_generator,\n",
    "                nb_val_samples=validation_generator.samples/batchsize)\n",
    "\n",
    "\n",
    "    model.save_weights(model_path)\n",
    "    \n",
    "\n",
    "load_model_and_finetune(InceptionV3,(299,299),'model/incepV3_e50.h5','model/incepV3_248.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# 直接通过 fine-tune 后的model来获取结果\n",
    "def write_gap_finetune(MODEL, image_size, model_path, lambda_func=None):\n",
    "    width = image_size[0]\n",
    "    height = image_size[1]\n",
    "    input_tensor = Input((height, width, 3))\n",
    "    x = input_tensor\n",
    "    if lambda_func:\n",
    "        x = Lambda(lambda_func)(x)\n",
    "    base_model = MODEL(input_tensor=x, include_top=False)\n",
    "\n",
    "    # add a global spatial average pooling layer\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    # let's add a fully-connected layer\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    # and a logistic layer -- let's say we have 200 classes\n",
    "    predictions = Dense(30, activation='softmax')(x)\n",
    "\n",
    "    # this is the model we will train\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    # 读取参数\n",
    "    model.load_weights(model_path)\n",
    "\n",
    "    gen = ImageDataGenerator()\n",
    "#     train_generator = gen.flow_from_directory(path+\"image\", image_size, shuffle=False,\n",
    "#                                               batch_size=16)\n",
    "    test_generator = gen.flow_from_directory(path+\"test_A\", image_size, shuffle=False,\n",
    "                                             batch_size=16, class_mode=None)\n",
    "\n",
    "#     train = model.predict_generator(train_generator)\n",
    "    test = model.predict_generator(test_generator)\n",
    "#     with h5py.File(\"./model/gap_finetune_%s.h5\"%MODEL.func_name) as h:\n",
    "#         h.create_dataset(\"train\", data=train)\n",
    "#         h.create_dataset(\"test\", data=test)\n",
    "#         h.create_dataset(\"label\", data=train_generator.classes)\n",
    "    return test\n",
    "\n",
    "\n",
    "result = write_gap_finetune(InceptionV3,(299,299),'model/incepV3_e50.h5',inception_v3.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0   1         2\n",
      "0      3108   1  0.031549\n",
      "1      3108   2  0.031549\n",
      "2      3108   3  0.031549\n",
      "3      3108   4  0.031549\n",
      "4      3108   5  0.031549\n",
      "5      3108   6  0.031549\n",
      "6      3108   7  0.031549\n",
      "7      3108   8  0.031549\n",
      "8      3108   9  0.031549\n",
      "9      3108  10  0.031549\n",
      "10     3108  11  0.031549\n",
      "11     3108  12  0.031549\n",
      "12     3108  13  0.031549\n",
      "13     3108  14  0.031549\n",
      "14     3108  15  0.031549\n",
      "15     3108  16  0.085076\n",
      "16     3108  17  0.031549\n",
      "17     3108  18  0.031549\n",
      "18     3108  19  0.031549\n",
      "19     3108  20  0.031549\n",
      "20     3108  21  0.031549\n",
      "21     3108  22  0.031549\n",
      "22     3108  23  0.031549\n",
      "23     3108  24  0.031549\n",
      "24     3108  25  0.031549\n",
      "25     3108  26  0.031549\n",
      "26     3108  27  0.031549\n",
      "27     3108  28  0.031549\n",
      "28     3108  29  0.031549\n",
      "29     3108  30  0.031549\n",
      "...     ...  ..       ...\n",
      "89970  4593   1  0.031549\n",
      "89971  4593   2  0.031549\n",
      "89972  4593   3  0.031549\n",
      "89973  4593   4  0.031549\n",
      "89974  4593   5  0.031549\n",
      "89975  4593   6  0.031549\n",
      "89976  4593   7  0.031549\n",
      "89977  4593   8  0.031549\n",
      "89978  4593   9  0.031549\n",
      "89979  4593  10  0.031549\n",
      "89980  4593  11  0.031549\n",
      "89981  4593  12  0.031549\n",
      "89982  4593  13  0.085076\n",
      "89983  4593  14  0.031549\n",
      "89984  4593  15  0.031549\n",
      "89985  4593  16  0.031549\n",
      "89986  4593  17  0.031549\n",
      "89987  4593  18  0.031549\n",
      "89988  4593  19  0.031549\n",
      "89989  4593  20  0.031549\n",
      "89990  4593  21  0.031549\n",
      "89991  4593  22  0.031549\n",
      "89992  4593  23  0.031549\n",
      "89993  4593  24  0.031549\n",
      "89994  4593  25  0.031549\n",
      "89995  4593  26  0.031549\n",
      "89996  4593  27  0.031549\n",
      "89997  4593  28  0.031549\n",
      "89998  4593  29  0.031549\n",
      "89999  4593  30  0.031549\n",
      "\n",
      "[90000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "def getResult(output_path,y_pred):\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    \n",
    "    path = './data/test_A/test'\n",
    "    filename = []\n",
    "    for file in os.listdir(path):\n",
    "        filename.append(file)\n",
    "\n",
    "    f = []\n",
    "    for s in filename:\n",
    "        for i in range(30):\n",
    "            f.append(s.split('.')[0])\n",
    "\n",
    "    index = [i for i in range(1,31)]*len(filename)\n",
    "\n",
    "    y_pred = y_pred.clip(min=0.003, max=0.995)\n",
    "\n",
    "    import numpy as np\n",
    "    def softmax(x):\n",
    "        \"\"\"Compute the softmax of vector x.\"\"\"\n",
    "        exp_x = np.exp(x)\n",
    "        softmax_x = exp_x / np.sum(exp_x)\n",
    "        return softmax_x\n",
    "\n",
    "    for y in range(len(y_pred)):\n",
    "        y_pred[y] = softmax(y_pred[y])\n",
    "\n",
    "\n",
    "    prob = [list(y_pred[j]) for j in range(len(y_pred))]\n",
    "    probs = []\n",
    "    for p in prob:\n",
    "        probs.extend(p)\n",
    "\n",
    "    pd.DataFrame({'f':f,'index':index,'probs':probs}).to_csv(output_path,header=None,index=None)    \n",
    "    print(pd.read_csv(output_path,header=None))\n",
    "\n",
    "    \n",
    "getResult('result/incepV3_e50_finetune.csv',result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08507601916789999"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "a = pd.read_csv('result/incepV3_e50_finetune.csv',header=None)\n",
    "max(a.iloc[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 记录\n",
    "# 不去先训练全连接层的情况下直接去微调后几层，效果还不错，还得试一试先训练50个epoch再去微调的效果。\n",
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
